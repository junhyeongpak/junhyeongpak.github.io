---
layout: single
title: "ML KNN"

---

#  기계학습 방법론과 KNN

- 지도 학습(Supervised Learning)
- 비지도 학습(Unsupervised Learning)
- 강화학습(Reinforcement Learning)

-> 지도학습과 비지도 학습의 가장 큰 차이점은 학습시 Labels 여부임

---

## Supervised Learning Framework

### Data-driven Approach

- Step 1: Design the form of a model: $$ e.g., \hat{f}(x) $$
- Step 2: Definee the goal of the model: $$ e.g., y \approx \hat{f}(x) $$
- Step 3: Find the parameters of $$ \hat{f}(x)$$ that best achieves the goal with trainig data, $$ \{(x_i, y_i):i=1, ..., n\} $$
- Step 4: Given an unseen x, estimate its label $$ \hat{y}$$ by computing $$\hat{y} =\hat{f}(x)$$ 

---

### 강화학습

어떤 에이전트가 상호작용 환경에서 보상과 벌을 긍정과 부정의 신호로써 인간의 의도 또는 작업을 달성하기 위해 명확히 프로그래밍 하는 것 없이 사용해서 반복된 시도와 실패를 통해 작업을 수행하도록 학습시키는 것 

### 강화학습 특성

에이전트는 무작위 환경으로부터 상화작용하며 학습함

- 지도가 없으며, 오직 보상 신호만 존재함
- 피드백은 지연된 형태로 제공됨
- 순차적인 의사결정
- 액션이 관찰값에 영향을 미치므로 독립적이도 않고 동일한 분포를 따르지 않음

---

# KNN(K-Nearest Neighbors)

## KNN의 개념

- 특정자료의 분류기준을 정할 때, 주변 k개의 데이터가 속하는 클래스(class)들 중에서 가장 많은 클래스로 특정자료를 분류하는 방식

### KNN의 개념

- 게으른 학습(Lazy Learner)
  - 'lazy': 훈련 데이터로부터 수학적 모형인 판별 함수를 학습하지 않음
  - 대신, 훈련 데이터 셋을 메모리에 저장
- 사례중심학습(instance-based learning)
  - 훈련데이터 자체가 모형이므로 어떠한 추정 방법도 모형도 없음
  - 즉, 데이터 분포를 표현하기 위한 파라미터 추정이 필요 없음
- 간단한 방법이지만 성능면에서 괜찮은 편임
- 차원의 저주(curse of dimension)
  - 데이터 차원이 증가할수록 성능저하가 심함
  - 동일한 수의 데이터 밀도는 차원이 증가할수록 해당 공간의 부피가 기하급수적으로 증가하므로 sparse해짐
  - 즉, 차원이 증가할수록 데이터 분포 분석에 필요한 샘플 데이터의 수가 기하급수적으로 증가
- Minkowski distance
  - i번째 관측치와 j번째 관측치의 거리 측정
  - $d(x_i, x_j)=\sqrt[p]{\Sigma_n|x_{in}-x_{jn}|^p}, \,where \, x_i,x_j \, \in \, \mathbb{R}^n$
    - If p = 1, 맨해튼 거리
    - if p = 2, 유클리디안 거리

- 탐색할 이웃의 수(k)와 거리측정방법

  - k값이 작은 경우: 과대적합(overfitting) 발생 - 데이터의 지역적 특성을 지나치게 반영

  - k값이 큰 경우: 과소적합(underfitting) 발생 - 표현력 상실

  - |              | Bias | Variance | Complexity | Flexibility | Generalizability |
    | ------------ | ---- | -------- | ---------- | ----------- | ---------------- |
    | Underfitting | High | Low      | Low        | Low         | High             |
    | Overfitting  | Low  | High     | High       | High        | Low              |

---

## KNN의 k가 갖는 의미는?

- 새로운 테스트 자료에 대해 k의 개수에 따라 분류 결과가 달라짐
  - 다수결 방식(Majority voting): 이웃의 범주 중에서 제일 많은 범주로 새 데이터의 범주 분류
- 가중합 방식(Weighted voting): 가까운 이웃의 정보에 좀 더 높은 가중치 부여
  - 새로운 데이터의 범주 불변

---

## KNN의 장단점

- 장점
  - 학습데이터 내에 끼어있는 노이즈의 영향을 크게 받지 않음
  - 학습데이터 수가 많다면 꽤 효과적인 알고리즘
- 단점
  - 최적 이웃의 수(k)와 어떤 거리 척도(distance metric)가 분석에 적합한지 불분명해 데이터 각각의 특성에 맞게 연구자가 임의로 선정해야 함
    - Best k는 데이터마다 다르기 때문에 Grid search를 활용해야 함..
  - 새로운 관측치와 각각의 학습 데이터 사이의 거리를 전부 측정해야 하므로, 계산 시간이 오래 걸리는 한계가 있음
  - KNN의 계산 복잡성을 줄이려는 시도 -> LSH 등등

---

# 데이터 분할

## 데이터 분할

- 학습 데이터와 시험 데이터가 서로 겹치치 않게 나누는 것

## 데이터 분할의 목적

- 학습 데이터로 모델을 학습시키고, 학습에 전혀 사용하지 않은 시험데이터에 적용하여 학습결과의 일반화가 가능한지 알아보기 위함
- 검증 데이터: 학습이 완료된 모델을 검증하기 위한 데이터셋으로 모델을 update시키는 용도로 활용(epoch, 학습률, 정규화, 조기 종료 등등)
  - 모델이 과적합 되었다면, validation 데이터셋으로 검증 시에 에러율이 높아지는 현상을 확인할 수 있고, 이런 현상이 나타나면 학습을 종료
- 테스트 데이터: 학습에 전혀 관여하지 않고, '최종 성능'을 평가하기 위한 용도로 활용

---

# 결과 분석

- 성능 평가
  - 분류 문제는 회귀 분석과 달리 다양한 성능 평가 기준(metric)이 필요
  - 평가 방법마다 장단점 존재
- Scikit_Learn에서 제공하는 분류 성능 평가 방법
  - 혼동행렬
  - accuracy
  - precision
  - recall
  - F1 score
  - Roc_curve
  - Auc

---

### 혼합행렬(Confusion Matrix)

- 실제 클래스와 모델이 예측한 클래스가 일치하는 빈도를 행렬도 나타냄

### 정확도(Accuracy)

- 전체 샘플 중 맞게 예측한 샘플 수의 비율
- $accuracy = \frac{TP + TN}{TP+TN+FP+FN}$

### 정밀도(Precision)

- 양성 클래스에 속한다고 예측한 표본 중에서 실제 양성 클래스에 속하는 표본 수의 비율
- $precision=\frac{TP}{TP+FP}$

### 재현율(Recall)

- 실제 양성 클래스에 속한 표본 중에 양성 클래스에 속한다고 예측한 표본 수의 비율
- $recall=\frac{TP}{TP+FN}$

### F1-Score

- 정확도와 재현율의 조화평균(harmonic mean)
- $F1=\frac{2}{\frac{1}{Precision}+\frac{1}{Recall}}=2\times\frac{Precision\times Recall}{Precision+Recall}$

### ROC curve

- 이진 분류기의 성능을 threshold(임계값)에 따라 FPR(x축)과 TPR(y축)의 변화를 표현

- $TPR=\frac{TP}{P}=\frac{TP}{TP+FN}=Sensitivity(민감도)$

- $TNR=\frac{TN}{N}=\frac{TN}{FP+TN}=Specificity(특이도)$

- $FPR=\frac{FP}{N}=\frac{FP}{FP+TN}=1-TNR=1-Specificity$

  FPR을 x축으로 두고 TPR을 y축으로 두는 그래프

### AUC

ROC 커브의 아래 영역이 넓을수록 성능이 좋음

