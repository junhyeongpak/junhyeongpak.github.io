---
layout: page
title: "Random Forest Review"
description: "Random Forest 논문 리뷰"
tage: [ML]
comment: true
published: true
categories: ML
---

# Random Forest Review

---

## Abstract

랜덤 포레스트는 각 트리가 독립적으로 샘플링 된 랜덤 벡터에 의존하는 트리 예측의 조합으로 구성된다. 랜덤포레스트의 일반화 오차는 트리 수가 증가함에 따라 수렴하며, 이는 포레스트의 각 개별 트리의 정확도와 상관관계에 따라 달라진다. 노드 분할시 랜덤한 특징을 선택하면 AdaBoost와 비교해 낮은 오차율을 유지하면서도 잡음에 더 강건한 성능을 보인다. 내부 추정치를 통해 오류, 강도, 상관관계를 모니터링하고 이를 통해 분할에 사용되는 특징 수가 증가함에 따른 반응도 확인할 수 있다.

---

## 1. Introduction

분류 정확도를 크게 향상시키기 위해서 여러 개의 트리를 생성하여 가장 많이 선택된 클래스로 투표하는 방식의 앙상블 기법이 개발되었다. 이러한 앙상블을 구성하려면 각 트리의 성장을 제어하는 랜덤 벡터를 생성하는데, 대표적으로 배깅(bagging)을 사용한다. 배깅은 학습 데이터에서 무작위로 표본을 선택하여 트리를 생성하며, 각 노드에서 K개의 최적 분할 중 하나를 무작위로 선택하는 방식이 사용된다. 또한, 트리 학습 시 각 노드에서 사용할 특징의 무작위 하위 집합을 선택하는 방법도 제안되었다.

이러한 접근법들의 공톰점은 각 트리가 고유한 랜덤 벡터에 따라 독립적으로 생성된다는 점이며, 최종적으로 가장 많은 투표를 받은 클래스를 선택하는 랜덤 포레스트방식이라는 것이다.

더 자세히 말하면 k번째 나무에 대해 랜덤 벡터 $\theta_k$가 생성되고 이 벡터는 $\theta_1, \theta_2, ..., \theta_{k-1}$과는 독립이지만 동일한 분포를 갖는다. 그리고 개별 트리는 학습 데이터와 $\theta_k$를 이용해 분류기 $h(x, \theta_k)$를 만든다.

이렇게 생성된 랜덤 벡터를을 활용해서 다수의 분류 트리를 생성하고 이 트리를 활용해 클래스를 예측한 뒤 다수결로 얻어진 클래스를 최종 라벨로 선정한다. 이러한 전반적인 과정을 랜덤 포레스트(Random Forest)라 일컫는다.

랜덤 포레스트는 트리의 개수가 많아질수록 과적합 문제를 줄이고, 개별 트리의 정확성과 상관성에 따라 분류 성능이 결정된다.

---

## 2. Characterizing the accuracy of Random Forests

### 2.1 Random Forests Convergence

랜덤 포레스트는 트리의 수가 증가함에 따라 과적합 없이 일반화 오차가 안정화되며, 이는 대수의 법칙을 통해 설명된다. 트리의 수가 무한대로 증가할 때, 랜덤포레스트의 예측은 수렴하여 일반화 오차가 일정한 한계값에 도달하게 된다.

$$
\lim_{N\rightarrow\infin}P(\frac{1}{N}\sum_{i=1}^Nh_i(X)=Y)=P(h(X)=Y)
$$

- 여기서 $h_i(X)$는 i-번째 트리의 예측이며, $h(X)$는 랜덤 포레스트의 최종 예측을 의미한다.

### 2.2 Strength and Correlation

랜덤 포레스트의 정확도는 개별 트리의 강도와 트리 간 상관관계에 의해 결정된다. 강도는 개별 트리가 얼마나 정확한지를 나타내며, 상관관계는 트리 간 예측의 유사성을 의미한다. 이 두 요소는 일반화 오차와 직접적인 관계가 있다.

- 강도(Strength) s: 개별 트리의 예측 정확도를 측정하며, 다음과 같이 정의됨

  $$
  s = \mathbb{E}_{X,Y}[mr(X,Y)]
  $$

  $$
  mr(X,Y)=P_{\theta}(h(X,\theta)=Y)-\max_{j\neq Y}P_{\theta}(h(X, \theta)=j)
  $$

  여기서 $mr(X,Y)$는 랜덤 포레스트의 마진 함수로, 모델의 각 입력 X에 대한 올바른 예측 확률과 최대의 오차 확률 차이를 나타낸다.

- 상관관계(Correlation) $\rho$: 트리 간 예측의 유사성을 나타내며, 일반화 오차를 줄이기 위해서는 낮은 상관관계가 필요하다.

  $$
  \rho = \frac{var(mr)}{s^2}
  $$

  이 두 요소가 일반화 오차에 미치는 영향은 다음과 같은 식으로 표현된다.

  $$
  PE^* \leq \bar\rho\frac{(1-s^2)}{s^2}
  $$

  일반화 오차 PE*는 마진이 음수일 확률로 정의되며, 강도가 높을수록 PE*는 작아지고 상관관계가 낮을수록 PE\*는 줄어든다.

  여기서 $\bar\rho$는 각 트리의 상관관계의 평균이다.

  ***

  ## 3. Using Random Features

  이전의 랜덤 포레스트 연구들은 일반화 오류 관점에서 AdaBoost를 뛰어 넘지 못했다. 정확도를 향상시키기 위해서는 랜덤 포레스트에 포함된 Randomness가 개별 분류기의 strength를 유지하면서 분류기들의 상관성을 줄여야 한다. 따라서 포레스트는 각 노드에서 무작위로 선택된 입력 또는 입력 조합을 사용하여 각 트리를 성장시키는 방식으로 구성된다. 이 방식을 활용하면 AdaBoost와 비견될 만한 정확도를 제공한며 다음과 같은 특징을 가지고 있다.

  I) AdaBoost와 유사하거나 때로 더 정확한 성능을 보인다.

  II) 이상치와 노이즈에 대해 강건하다.

  III) Bagging이나 Boosting에 비해 빠름

  IV) 오류, 강도, 상관 및 변수 중요성에 대한 유용한 내부 추정치를 제공한다.

  V) 단순하고 쉽게 병렬 처리할 수 있다.

  ***

  ### 3.1 오차, 강도 및 상관을 모니터링하기 위한 out-of-bag 추정치 사용

  랜덤 포레스트에서, bagging은 랜덤 특성 선택과 함께 사용된다. 각 새로운 훈련 세트는 원래 훈련 세트에서 중복 추출을 통해 만들어지고, 이 새로운 학습 세트를 사용하고 랜덤 특성을 통해 트리를 성장시키고 생성된 트리는 가지치기 하지 않는다.

  bagging을 사용하는 데에는 두 가지 이유가 있다. 첫째, 랜덤 특성을 사용할 때 bagging을 사용하면 정확도가 향상되는 경향이 있기 때문이다. 둘째, bagging은 결합된 트리 앙상블의 일반화 오차(PE\*)와 강도 및 상관관계에 대한 추정치를 지속적으로 제공할 수 있기 때문이다.

  bagging을 통해서는 각 Bootstrap(중복을 허용하는 샘플링)을 하며 복원추출에 뽑히지 않은 데이터(보통 2/3정도가 뽑히고 1/3이 안뽑힌다)가 자동으로 validation set가 되어 cross-validation을 하지 않아도 test error를 추정할 수 있다. 이 뽑히지 않은 데이터를 out-of-bag라 부른다.

  ***

  ## 4. Random Forests using Random Input Selection

  가장 간단한 랜덤 포레스트 방법은 각 노드에서 무작위로 선택된 소수의 노드만을 사용해 분할에 사용한다. 이 방법은 CART 방식으로 최대 크기까지 나무를 성장시키고 가지치기를 시행하지 않는다. 이 방법을 Forest-RI라고 한다. 선택된 입력 변수의 수 F는 고정된다. 여기서 F = 1로 사용하거나 F = $\log_2M+1$로 설정한다.

  실혐 결과 랜덤 포레스트의 일반화 오류는 AdaBoost와 비슷하다.

  하지만 Random Forest의 경우에는 훈련하는 데이터 세트가 2/3정도의 데이터이며 소수의 입력 변수만을 선택하기 때문에 사용한 트리의 수가 랜덤 포레스트가 2배정도 더 많다.

  ***

  ## 5. Random Forests Using Linear Combinations of Inputs

  변수가 많이 없는 상황에서 변수를 무작위로 고르면 나무들 간의 강도가 높아질 수는 있지만 상관성이 증가할 수 있다. 이 때 F보다 작은 L개의 변수를 무작위로 선택하고 각 변수를의 선형 결합에 균일 분포를 만족하는 절편항을 더해주는 방식으로 F개의 선형 결합을 뽑고 그 중에서 최적 분리를 찾아내는 방식도 있다. 이러한 방식을 Forest-RC라고 부른다.

  ### 5.1 Categorical Variables

  선형 결합을 할 때, 연속형 변수가 아닌 범주형 데이터가 포함되어 있는 경우에 One-Hot 인코딩을 활용해 이를 연속형 변수 취급한다.

  ***

  ## 6. Empirical Results on Strength and Correlation

  이 절에서는 강도와 상관관계가 일반화 오차에 미치는 영향을 조사한다. 또한 F의 크기에 대한 일반화 오차의 민감도 부족에 대해서도 더 깊이 이해하고자 한다. Out-of-bag 추정치를 사용해 강도와 상관관계를 추정했다.

  실험 결과 일반화 오차가 낮은 더 좋은 랜덤 포레스트는 분류기들 간의 상관관계가 낮고 강도가 높음을 나타낸다. 트리 생성에서 사용되는 무작위성은 상관관계 $\rho$를 낮추고 합리적인 강도를 유지하도록 한다.

  ***

  ## 7. Conjecture: Adaboost is a Random Forest

  Adaboost는 특정 조건에서 랜덤 포레스트와 유사하게 작동한다. 이를 통해 Adaboost가 과적합되지 않음을 보여준다.

  ***

  ## 8. The Effects of Output Noise

  Dietterich(1998)은 학습 세트 일부 출력 레이블이 무작위로 변경되는 Noiser가 발생하면, AdaBoost의 정확도가 급격히 저하되는 반면, Bagging과 랜덤 분할 선택은 노이즈에 더 강하다는 것을 보여주었다. 실제로 출력에 약간의 노이즈가 존재하는 경우가 많으므로, 노이즈에 대한 강건성은 바람직한 특성이다.

  AdaBoost는 잘 못 분류된 인스턴스의 가중치를 점진적으로 증가시켜 잘못된 클래스 레이블을 가진 인스턴스를 지속적으로 오분류 할 것이다. 그러나 랜덤 포레스트 방식은 특정 인스턴스에 집중하지 않으므로 노이즈의 영향이 적다.

  ***

  ## 9. Data with Many Weak Inputs

  의료 진단이나 문서 검색과 같은 분야에서는 다수의 약한 특성(개별적으로는 클래스나 목표 변수를 잘 예측하지 못하는 변수; 불충분한 정보)가 흔해지고 있다. 이러한 데이터셋의 공통된 특징은 개별 입력 변수나 소규모 변수 그룹만으로는 클래스를 효과적으로 구분하기 어렵다는 점이다. 이와 같은 데이터는 전통적인 분류기(예: 결정트리)로는 처리하기 까다롭다.

  하지만 랜덤 포레스트는 그러한 변수를 찾을 수 있었다. 분리 시마다 랜덤하게 뽑는 변수의 개수를 조절해 이러한 상황에서 테스트 오류를 줄일 수 있음을 보였다. 개별 분류기의 테스트 오류는 높았으나 모이니까 성능 좋은 분류기가 된다.

  ***

  ## 10. Exploring the Random Forest Mechanism

  랜덤 포레스트는 해석을 하는 부분이 어렵다. 이러한 점을 보완하기 위해 변수 중요도를 계산하는 과정을 제안한다. 한 변수가 중요하면 이 변수와 상관성이 높은 변수는 상대적으로 중요하지 않게 나온다.

  ***

  ## 11. Random Forests for Reggression

  랜덤 포레스트를 회귀 문제에 적용시키며 일반화 오류에 대한 상한을 제시한다. 이러한 상한도 각 회귀 나무들 간 상관성과 개별 나무들의 오류에 의존한다.

  ***

  ## 12. Empirical Results in Regression

  회귀에서 랜덤 포레스트는 배깅과 랜덤 특성 선택을 결합해 성능을 개선할 수 있으며, Out-of-Bag 추정을 통해 모델의 오류와 상관관계를 모니터링할 수 있다.

  특성의 수가 증가할수록 개별 트리의 오류는 감소하지만, 상관관계가 점진적으로 증가하기 때문에, 특성 수를 적절히 조정하는 것이 좋다.

  출력 노이즈 추가는 특정 상황에서 배깅보다 낮은 오류율을 보여주며, 랜덤 포레스트가 다양한 무작위 요소를 통해 성능을 최적화할 수 있는 유연성을 가지고 있음을 시사한다.

  ***

  ## 13. Remarks and Conclusions

  랜덤 포레스트는 예측을 위한 효과적인 도구다. 대수의 법칙으로 인해 랜덤 포레스트는 과적합을 잘 일으키지 않고 무작위성을 잘 활용하면 분류 및 회귀 문제에서 좋은 성능을 보여준다.
